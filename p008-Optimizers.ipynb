{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Optimizers__\n",
    "\n",
    "We already implemented something along the lines of an optimizer, in our training loop. But now, we will be creating a class for the optimizer. The kind of optimizer we are dealing with is called Gradient Descent. Gradient Descent is a form of optimization, that uses the gradients of weights and biases, to take incremental steps towards the minima of the loss function, in an effort to decrease loss. Let's create a class called Gradient Descent, to represent this. We will set default LR as 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer_GD:\n",
    "  def __init__(self, learning_rate=0.001):\n",
    "    self.learning_rate = learning_rate\n",
    "  def update_params(self, layer):\n",
    "    layer.weights -= self.learning_rate * layer.dweights\n",
    "    layer.biases -= self.learning_rate * layer.dbiases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Decay and Momentum__\n",
    "\n",
    "Let's first talk about decay. Let's say we start off with a high learning rate, so we can jump quickly towards the global minimum of the cost function. But as we get closer, we may want to decrease our learning rate, since we don't want to jump around the cost function as much. To lower the learning rate over iterations is known as decay. The formula for decay is given below.\n",
    "\n",
    "#### $LR = \\frac {LR}{(1 + R_{d} t)}$\n",
    "\n",
    "Here $R_{d}$ represents the rate of decay, and $t$ represents number of iterations. \n",
    "\n",
    "Now let's talk about momentum. Let's say we have a cost function, with multiple local minimas. When trying to approach the global minimum, this can be an issue, because our model can essentially get stuck in a local minima. To fix this, we implement an idea called momentum, which is a technique that is used to nudge the model parameters from local minimas, Imagine a ball rolling down a hill. As it rolls, it gains momentum and goes faster and faster until it reaches the bottom. In the context of optimization, the \"hill\" represents the minimum, and the \"ball\" represents our model trying to find the minimum. The formula for momentum is given below\n",
    "\n",
    "$M = M \\times \\beta - a \\times \\nabla(\\theta)$\n",
    "\n",
    "$\\theta = \\theta + M$\n",
    "\n",
    "Here $\\theta$ is our parameters, $a$ is the learning rate. $M$ is our momentum term for the parameters. Now we can apply both these concepts to update our optimizer class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer_GD:\n",
    "  def __init__(self, learning_rate=1e-3, decay=0., momentum=0.):\n",
    "    self.learning_rate = learning_rate\n",
    "    self.current_learning_rate = learning_rate\n",
    "    self.decay = decay\n",
    "    self.momentum = momentum\n",
    "    self.iterations = 0\n",
    "  def update_params(self, layer):\n",
    "    if self.decay:\n",
    "      self.current_learning_rate = self.learning_rate / (1 + self.decay * self.iterations)\n",
    "    if self.momentum:\n",
    "      if not hasattr(layer, 'weight_momentums'):\n",
    "        layer.weight_momentums = np.zeros_like(layer.weights)\n",
    "        layer.bias_momentums = np.zeros_like(layer.biases)\n",
    "      weight_updates = layer.weight_momentums * self.momentum - self.current_learning_rate * layer.dweights\n",
    "      layer.weight_momentums = weight_updates\n",
    "      bias_updates = layer.bias_momentums * self.momentum - self.current_learning_rate * layer.dbiases\n",
    "      layer.bias_momentums = bias_updates\n",
    "    else:\n",
    "      weight_updates = -self.current_learning_rate * layer.dweights\n",
    "      bias_updates = -self.current_learning_rate * layer.dbiases\n",
    "    layer.weights += weight_updates\n",
    "    layer.biases += bias_updates\n",
    "    self.iterations += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have updated our Gradient Descent class. First, if the decay is a set parameter, we use the decay formula, to change the learning rate. Next, we initialize the momentums of our parameters, if they are not already there. Then using the momentum formula and gradients, we set our momentum, and use that to update our parameters. Now let's test it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.53005, Accuracy: 84.38%\n",
      "Epoch 2/10, Loss: 0.26834, Accuracy: 93.75%\n",
      "Epoch 3/10, Loss: 0.26827, Accuracy: 96.88%\n",
      "Epoch 4/10, Loss: 0.20454, Accuracy: 96.88%\n",
      "Epoch 5/10, Loss: 0.23371, Accuracy: 96.88%\n",
      "Epoch 6/10, Loss: 0.23881, Accuracy: 87.50%\n",
      "Epoch 7/10, Loss: 0.08769, Accuracy: 96.88%\n",
      "Epoch 8/10, Loss: 0.49848, Accuracy: 84.38%\n",
      "Epoch 9/10, Loss: 0.22595, Accuracy: 90.62%\n",
      "Epoch 10/10, Loss: 0.11739, Accuracy: 96.88%\n",
      "Test Loss: 0.32194\n",
      "Test Accuracy: 90.96%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pickle\n",
    "with open('dataset.p', 'rb') as file:\n",
    "  X, y = pickle.load(file)\n",
    "X = X.reshape(X.shape[0], -1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "optimizer = Optimizer_GD(decay=1e-5, momentum=1e-3)\n",
    "\n",
    "layer_one = Dense(784, 128)\n",
    "relu_one = ReLu()\n",
    "layer_two = Dense(128, 64)\n",
    "relu_two = ReLu()\n",
    "layer_three = Dense(64, 10)\n",
    "softmax_loss = Softmax_Loss()\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "for epoch in range(epochs):\n",
    "  indices = np.arange(len(X_train))\n",
    "  np.random.shuffle(indices)\n",
    "  X_train, y_train = X_train[indices], y_train[indices]\n",
    "  \n",
    "  for i in range(0, len(X_train), batch_size):\n",
    "    X_batch, y_batch = X_train[i:i+batch_size], y_train[i:i+batch_size]\n",
    "     \n",
    "    layer_one.forward(X_batch)\n",
    "    relu_one.forward(layer_one.output)\n",
    "    layer_two.forward(relu_one.output)\n",
    "    relu_two.forward(layer_two.output)\n",
    "    layer_three.forward(relu_two.output)\n",
    "    loss = softmax_loss.forward(layer_three.output, y_batch)\n",
    "\n",
    "    predictions = np.argmax(softmax_loss.output, axis=1)\n",
    "    accuracy = np.mean(predictions == y_batch)\n",
    "\n",
    "    softmax_loss.backprop(softmax_loss.output, y_batch)\n",
    "    layer_three.backprop(softmax_loss.dinputs)\n",
    "    relu_two.backprop(layer_three.dinputs)\n",
    "    layer_two.backprop(relu_two.dinputs)\n",
    "    relu_one.backprop(layer_two.dinputs)\n",
    "    layer_one.backprop(relu_one.dinputs)\n",
    "\n",
    "    optimizer.update_params(layer_one)\n",
    "    optimizer.update_params(layer_two)\n",
    "    optimizer.update_params(layer_three)\n",
    "\n",
    "  print(f'Epoch {epoch+1}/{epochs}, Loss: {loss:.5f}, Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "layer_one.forward(X_test)\n",
    "relu_one.forward(layer_one.output)\n",
    "layer_two.forward(relu_one.output)\n",
    "relu_two.forward(layer_two.output)\n",
    "layer_three.forward(relu_two.output)\n",
    "\n",
    "test_loss = softmax_loss.forward(layer_three.output, y_test)\n",
    "print(f'Test Loss: {test_loss:.5f}') \n",
    "\n",
    "predictions = np.argmax(softmax_loss.output, axis=1) \n",
    "accuracy = np.mean(predictions == y_test)\n",
    "print(f'Test Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright so it looks like our mode along with momentum and decay, did slightly increase our accuracy on the training and testing datasets, but let's look at a better optimizer.\n",
    "\n",
    "## __AdaGrad and RMSProp__\n",
    "\n",
    "AdaGrad is a type of optimizer, that instead of having a general learning rate for all parameters, has a per-parameter learning rate. During the training process, some weights can rise significantly more than others, and this can be a problem. To fix this, AdaGrad adapts learning rates of parameters by scaling them inverselty proportional to the square root of the sum of thier squared values, so parameters that recieve small updates, will have their learning rate increased, and vice versa. \n",
    "\n",
    "$G = G + g^2$\n",
    "\n",
    "$\\theta = \\theta - \\frac {LR}{\\sqrt {G + e}} * g$\n",
    "\n",
    "Here first the entire sum gets updated by the square of current gradient. Then we update the parameters, by inversely scaling to this value, and adding a hyperparameter called epsilon, to avoid division by 0. Now we can implement this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer_AdaGrad:\n",
    "  def __init__(self, learning_rate=0.0001, epsilon=1e-7):\n",
    "    self.learning_rate = learning_rate\n",
    "    self.epsilon = epsilon\n",
    "  def update_params(self, layer):\n",
    "    if not hasattr(layer, 'weight_cache'):\n",
    "      layer.weight_cache = np.zeros_like(layer.weights)\n",
    "      layer.bias_cache = np.zeros_like(layer.biases)\n",
    "    \n",
    "    layer.weight_cache += layer.dweights ** 2\n",
    "    layer.bias_cache += layer.dbiases ** 2\n",
    "\n",
    "    layer.weights -= self.learning_rate * layer.dweights / np.sqrt(layer.weight_cache + self.epsilon)\n",
    "    layer.biases -= self.learning_rate * layer.dbiases / np.sqrt(layer.bias_cache + self.epsilon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's talk about problems with AdaGrad. The cache of the of sum of squared gradients, can get very large over time, causing learning rates to drop too much. This can slow down or halt learning during the training process. To fix this, we can introduce an optimizer called RMS_Prop, which introduces a moving average, which gives more weight to recent gradients, and helps in stopping learning rate from decreasing too fast. The only change is in the sum of the squared gradients, given below:\n",
    "\n",
    "$G = \\beta \\times G + (1 - \\beta) \\times g^2$\n",
    "\n",
    "$\\theta = \\theta - \\frac {LR}{\\sqrt {G + e}} * g$\n",
    "\n",
    "Here, $\\beta$ is a hyperparameter called rho. Now let's change the AdaGrad code a bit to make the RMSProp optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer_RMSProp:\n",
    "  def __init__(self, learning_rate=0.0001, epsilon=1e-7, rho=0.9):\n",
    "    self.learning_rate = learning_rate\n",
    "    self.epsilon = epsilon\n",
    "    self.rho = rho\n",
    "  def update_params(self, layer):\n",
    "    if not hasattr(layer, 'weight_cache'):\n",
    "      layer.weight_cache = np.zeros_like(layer.weights)\n",
    "      layer.bias_cache = np.zeros_like(layer.biases)\n",
    "    \n",
    "    layer.weight_cache = self.rho * layer.weight_cache + (1 - self.rho) * layer.dweights ** 2\n",
    "    layer.bias_cache = self.rho * layer.bias_cache + (1 - self.rho) * layer.dbiases ** 2\n",
    "\n",
    "    layer.weights -= self.learning_rate * layer.dweights / np.sqrt(layer.weight_cache + self.epsilon)\n",
    "    layer.biases -= self.learning_rate * layer.dbiases / np.sqrt(layer.bias_cache + self.epsilon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's test our optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.01153, Accuracy: 100.00%\n",
      "Epoch 2/10, Loss: 0.17010, Accuracy: 93.75%\n",
      "Epoch 3/10, Loss: 0.08582, Accuracy: 96.88%\n",
      "Epoch 4/10, Loss: 0.22914, Accuracy: 93.75%\n",
      "Epoch 5/10, Loss: 0.37356, Accuracy: 90.62%\n",
      "Epoch 6/10, Loss: 0.23639, Accuracy: 96.88%\n",
      "Epoch 7/10, Loss: 0.02806, Accuracy: 100.00%\n",
      "Epoch 8/10, Loss: 0.06333, Accuracy: 96.88%\n",
      "Epoch 9/10, Loss: 0.61633, Accuracy: 93.75%\n",
      "Epoch 10/10, Loss: 0.05929, Accuracy: 96.88%\n",
      "Test Loss: 0.25189\n",
      "Test Accuracy: 94.93%\n"
     ]
    }
   ],
   "source": [
    "optimizer = Optimizer_RMSProp()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "  indices = np.arange(len(X_train))\n",
    "  np.random.shuffle(indices)\n",
    "  X_train, y_train = X_train[indices], y_train[indices]\n",
    "  \n",
    "  for i in range(0, len(X_train), batch_size):\n",
    "    X_batch, y_batch = X_train[i:i+batch_size], y_train[i:i+batch_size]\n",
    "     \n",
    "    layer_one.forward(X_batch)\n",
    "    relu_one.forward(layer_one.output)\n",
    "    layer_two.forward(relu_one.output)\n",
    "    relu_two.forward(layer_two.output)\n",
    "    layer_three.forward(relu_two.output)\n",
    "    loss = softmax_loss.forward(layer_three.output, y_batch)\n",
    "\n",
    "    predictions = np.argmax(softmax_loss.output, axis=1)\n",
    "    accuracy = np.mean(predictions == y_batch)\n",
    "\n",
    "    softmax_loss.backprop(softmax_loss.output, y_batch)\n",
    "    layer_three.backprop(softmax_loss.dinputs)\n",
    "    relu_two.backprop(layer_three.dinputs)\n",
    "    layer_two.backprop(relu_two.dinputs)\n",
    "    relu_one.backprop(layer_two.dinputs)\n",
    "    layer_one.backprop(relu_one.dinputs)\n",
    "\n",
    "    optimizer.update_params(layer_one)\n",
    "    optimizer.update_params(layer_two)\n",
    "    optimizer.update_params(layer_three)\n",
    "\n",
    "  print(f'Epoch {epoch+1}/{epochs}, Loss: {loss:.5f}, Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "layer_one.forward(X_test)\n",
    "relu_one.forward(layer_one.output)\n",
    "layer_two.forward(relu_one.output)\n",
    "relu_two.forward(layer_two.output)\n",
    "layer_three.forward(relu_two.output)\n",
    "\n",
    "test_loss = softmax_loss.forward(layer_three.output, y_test)\n",
    "print(f'Test Loss: {test_loss:.5f}') \n",
    "\n",
    "predictions = np.argmax(softmax_loss.output, axis=1) \n",
    "accuracy = np.mean(predictions == y_test)\n",
    "print(f'Test Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice, it looks like we had an improvment in our training results! But now, we will be looking at the most widely used optimizer, Adam. It combines the ideas of RMSProp and Momentum, and adds correction for the initializing setting the momentums and caches to 0. \n",
    "\n",
    "## __Adam Optimizer__\n",
    "\n",
    "The adam optimizer combines features of RMSProp and Momentum, and is the most popular optimizer due to it's efficiency across different types of problems. Let' look at the mathematics behind Adam.\n",
    "\n",
    "Momentum\n",
    "$M = \\beta_{1} \\times M + (1 - \\beta_{1}) \\times g$\n",
    "\n",
    "Cache\n",
    "$G = \\beta_{2} \\times G + (1 - \\beta_{2}) \\times g^2$\n",
    "\n",
    "Corrected Momentum\n",
    "#### $\\hat M = \\frac {M}{1 - \\beta_{1}^t}$\n",
    "\n",
    "Correct Cache\n",
    "#### $\\hat G = \\frac {G}{1 - \\beta_{2}^t}$\n",
    "\n",
    "Update values\n",
    "#### $\\theta = \\theta - \\frac {LR}{\\sqrt {\\hat G} + e} \\times \\hat M$\n",
    "\n",
    "Now let's implement it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer_Adam:\n",
    "  def __init__(self, epsilon=1e-7, learning_rate=0.001, beta_1=0.9, beta_2=0.999):\n",
    "    self.learning_rate = learning_rate\n",
    "    self.epsilon = epsilon\n",
    "    self.beta_1 = beta_1\n",
    "    self.beta_2 = beta_2\n",
    "    self.iterations = 0\n",
    "  def update_params(self, layer):\n",
    "    if not hasattr(layer, 'weight_cache'):\n",
    "      layer.weight_cache = np.zeros_like(layer.weights)\n",
    "      layer.bias_cache = np.zeros_like(layer.biases)\n",
    "      layer.weight_momentums = np.zeros_like(layer.weights)\n",
    "      layer.bias_momentums = np.zeros_like(layer.biases)\n",
    "    layer.weight_momentums = self.beta_1 * layer.weight_momentums  + (1 - self.beta_1) * layer.dweights\n",
    "    layer.bias_momentums = self.beta_2 * layer.bias_momentums  + (1 - self.beta_2) * layer.dbiases\n",
    "    weight_momentums_corrected = layer.weight_momentums / (1 - self.beta_1 ** (self.iterations + 1))\n",
    "    bias_momentums_corrected = layer.bias_momentums / (1 - self.beta_2 ** (self.iterations + 1))\n",
    "    layer.weight_cache = self.beta_2 * layer.weight_cache + (1 - self.beta_2) * layer.dweights ** 2\n",
    "    layer.bias_cache = self.beta_2 * layer.bias_cache + (1 - self.beta_2) * layer.dbiases ** 2\n",
    "    weight_cache_corrected = layer.weight_cache / (1 - self.beta_2 ** (self.iterations + 1))\n",
    "    bias_cache_corrected = layer.bias_cache / (1 - self.beta_2 ** (self.iterations + 1))\n",
    "    layer.weights -= self.learning_rate * weight_momentums_corrected / (np.sqrt(weight_cache_corrected) + self.epsilon)\n",
    "    layer.biases -= self.learning_rate * bias_momentums_corrected / (np.sqrt(bias_cache_corrected) + self.epsilon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice, now we have finished implementing the Adam optimizer, let's test it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.81498, Accuracy: 71.88%\n",
      "Epoch 2/10, Loss: 0.63102, Accuracy: 84.38%\n",
      "Epoch 3/10, Loss: 0.13327, Accuracy: 90.62%\n",
      "Epoch 4/10, Loss: 0.01897, Accuracy: 100.00%\n",
      "Epoch 5/10, Loss: 0.07676, Accuracy: 96.88%\n",
      "Epoch 6/10, Loss: 0.14442, Accuracy: 96.88%\n",
      "Epoch 7/10, Loss: 0.02162, Accuracy: 100.00%\n",
      "Epoch 8/10, Loss: 0.16082, Accuracy: 96.88%\n",
      "Epoch 9/10, Loss: 0.09315, Accuracy: 96.88%\n",
      "Epoch 10/10, Loss: 0.00638, Accuracy: 100.00%\n",
      "Test Loss: 0.16481\n",
      "Test Accuracy: 95.86%\n"
     ]
    }
   ],
   "source": [
    "optimizer = Optimizer_Adam()\n",
    "\n",
    "layer_one = Dense(784, 128)\n",
    "relu_one = ReLu()\n",
    "layer_two = Dense(128, 64)\n",
    "relu_two = ReLu()\n",
    "layer_three = Dense(64, 10)\n",
    "softmax_loss = Softmax_Loss()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "  indices = np.arange(len(X_train))\n",
    "  np.random.shuffle(indices)\n",
    "  X_train, y_train = X_train[indices], y_train[indices]\n",
    "  \n",
    "  for i in range(0, len(X_train), batch_size):\n",
    "    X_batch, y_batch = X_train[i:i+batch_size], y_train[i:i+batch_size]\n",
    "     \n",
    "    layer_one.forward(X_batch)\n",
    "    relu_one.forward(layer_one.output)\n",
    "    layer_two.forward(relu_one.output)\n",
    "    relu_two.forward(layer_two.output)\n",
    "    layer_three.forward(relu_two.output)\n",
    "    loss = softmax_loss.forward(layer_three.output, y_batch)\n",
    "\n",
    "    predictions = np.argmax(softmax_loss.output, axis=1)\n",
    "    accuracy = np.mean(predictions == y_batch)\n",
    "\n",
    "    softmax_loss.backprop(softmax_loss.output, y_batch)\n",
    "    layer_three.backprop(softmax_loss.dinputs)\n",
    "    relu_two.backprop(layer_three.dinputs)\n",
    "    layer_two.backprop(relu_two.dinputs)\n",
    "    relu_one.backprop(layer_two.dinputs)\n",
    "    layer_one.backprop(relu_one.dinputs)\n",
    "\n",
    "    optimizer.update_params(layer_one)\n",
    "    optimizer.update_params(layer_two)\n",
    "    optimizer.update_params(layer_three)\n",
    "\n",
    "  print(f'Epoch {epoch+1}/{epochs}, Loss: {loss:.5f}, Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "layer_one.forward(X_test)\n",
    "relu_one.forward(layer_one.output)\n",
    "layer_two.forward(relu_one.output)\n",
    "relu_two.forward(layer_two.output)\n",
    "layer_three.forward(relu_two.output)\n",
    "\n",
    "test_loss = softmax_loss.forward(layer_three.output, y_test)\n",
    "print(f'Test Loss: {test_loss:.5f}') \n",
    "\n",
    "predictions = np.argmax(softmax_loss.output, axis=1) \n",
    "accuracy = np.mean(predictions == y_test)\n",
    "print(f'Test Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There we go! Our model has a near perfect accuracy on the training dataset, and a very high accuracy on the testing dataset. That's it for this project. There are two other notebooks, one with the full code, and one with all the math formulas important for this project. Also feel free, to clone this repository, and edit things according to your liking, such as adding functions to improve efficiency, or expanding with more optimizers and loss functions, and even try it on other datasets!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
